# 目的
コーディングテスト

WebAPIのサービス作成

# 内容物
- README.md これ
- setup.hs Pythonの環境構築
- .gitignore git_hubには上がらないもの
- app.py flaskで記述した処理が書かれたページ
- templates/ 表示用のHTMLページが保存されている。
- run.sh 実行するスクリプト

## templates

templates/

    |-mainpage.html

    |-number2kanji.html

    |-kanji2number.html

    |-erroe.html

# 動かし方
---初回-----

0. `./setup.sh`

---実行---

1. `./run.sh`


# 参考サイト

FlaskのAPIの例

https://qiita.com/tomson784/items/406281bef7a5b2eb3cd8

FlaskのAPIの例２

https://sitest.jp/blog/?p=10459ß

render_templateの利用

https://qiita.com/nagataaaas/items/4662237cfb7b92f0f839


第一回
ガイダンス
パターン認識に関する英語の論文を十分理解する
プログラムは関係の無い一切触れない

パターン認識の基礎となる数学的な考え方
英語の本を使って読んで、読み解く力をつける

式の説明などを読める力をつける　機械学習関係の
論文には式やアルゴリズムが出てくるがプログラムは出てこない

パターン認識について基礎となる数学的理論について英語で触れる

教科書はPattern Classificationを用いる
パターン認識の名著の１つ

基礎的なところから書いてる
PRMLよりは簡単

進め方
75131f0e.png

来週は１章を訳す

自分なりに噛み砕いて＋αする。
要点をまとめてスライドに落とす

教科書＋αをどうするか？

3c05f0ec.png

機械学習アウトライン
大量のデータがネットワークの中にあるのは事実
外に出ているのがデータなのか処理なのかの違いなだけ

データを集めて何かをするのがAI　処理もAI
集まった大量のデータがビッグデータ

ビッグデータは高速に大量のデータが物凄い早く積み上がっていく。
やりとり速度　貯蓄速度　貯蓄量　がビックデータの要素

データが無いとAI技術も発達しない　ビッグデータとAI両方があって予測などができる。

データが膨大なので人間による情報抽出は不可能
またデータは矛盾、曖昧、ノイズが含まれるので、機械学習が有望

機械学習の定義
タスクを遂行する適切なモデルを適切な特徴　から構築すること
タスクに応じて適切にモデルを作っていくことが大事

汎化性能が低い場合はただ記憶しているだけのようなものになる

学習に無いパターンでも正しそうな結果ができること　が機械学習の最大の目的である。

教師あり学習
識別（分類）
誤差が最小となるような特徴空間上の分離面　を求める
一般化は学習していないデータ　未知のデータに対してもあっている必要がある
データが間違っている可能性もあると考えるとそのデータ自体にノイズがあると考えて一般化の視点から

回帰
データの補完方法　スプライン補完やN次多項補完などをしてもデータに引っ張られてしまい
データが嘘だった場合にそのデータに過剰適合してタスクに対して求められたモデルは一般化されていない
無いところでそのモデルが正しいのか誤差が大きく無いのかなどを考える必要がある

教師無し学習
モデル推定＝クラスタリング
データが出てきた背景、現象を知るのがクラスタリング
傾向を導き出すときに使う
ビッグデータから特徴を導き出す

パターンマイニング
隠れた規則性を発掘
分析をした結果行動を起こすために行われる
中間手法
半教師あり学習
正解付きデータからそれらしさを作成する
それらしさから確定できるものにラベルを付けていく
最初のラベルが付いた識別に基づいてラベルが不明なものを明らかに
していくので、最初のラベルが正しく無いとどんどん間違った方法へ向かっていってしまう

強化学習
時々やってくるデータにから学習を行っていく
パターン認識
感知
データをそのまま取り込む　ハードウェアの物理的な要因が影響していくる
できるだけ簡単に良い結果を導き出したいならノイズが無い方がいい
解像度は高い方がいい
選べるならば最終的な機械学習の精度に関わってくるので選定しなきゃいけない
分割と統合
関係のない者は削除、有効な部分は統合
前処理
特徴抽出
深層学習によってここが簡単に行われる
常に深層学習ができるわけではないので、データが少ない場合にはうまく行かない
現実問題で少ないデータでやるときには深層学習が使えないなら機械学習で、
適切なものの特徴を抽出する必要がある
識別に無関係な特性から不変な特徴抽出をしなければならないので
識別対象、タスク、データに対する知識が必須
識別に関係ないものが変わってても影響を受けない特徴が望ましい
識別
特徴から最適なカテゴリに割り当て
基本的には確率　機械学習には確率　NNは確率を学習しているとは言えない
機械学習は確率モデル
後処理
識別結果の評価と採否の決定
識別結果の判断は非常に難しい
識別器の結果をどう採用するのかを考えるところが難しい
識別ができるという部分だけに注目されがちだが、どれにも着目して全てがうまく動いて実用的なシステム
が動く
設計の概念にすると
データ収集の設計
特徴選択の設計　
モデルの選択
識別器の訓練方法
評価方法　などなどを　処理の要素をどういう風に考えるか　が重要になってくる

データ収集については
データを集める前に　データの量、種類集めるのかを考える必要があることが難しい
特徴量の抽出方法は無数にあり、不変であることが求められる
様々なことを考慮して特徴を考えなければならない

モデルの選択
特徴を最適に表現するモデルの選択

NNは結果論から特徴量を獲得する
以前は、データの生成過程から特徴をモデル化する

特徴を十分に表現できているが、過学習が起こらないほど単純なモデルが望ましい

CloseTestは過学習かもしれないけど精度を確かめる上限値を試す　モデルが学習できているかを試す
OpenTestはモデルの汎化性能を試す

収集したデータをどうやって分けるかなどを考えるのも難しい　ホールドアウト法、クロスバリデーション
など
